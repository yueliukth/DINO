{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../scripts')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ipywidgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import prepare_datasets\n",
    "from main import parse_args\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c0a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(t):\n",
    "    array = torch.clip((t * 0.224) + 0.45, 0, 1).permute(1, 2, 0).numpy()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Model is going to be save in  /storage/yue/dino_models/vit_small_CBISDDSM_finetuning_official\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "ARGS ARE: \n",
      "{\n",
      "    \"start_training\": {\n",
      "        \"mode\": \"train_finetuning\",\n",
      "        \"eval\": {\n",
      "            \"choices\": [\n",
      "                \"if_knn\"\n",
      "            ],\n",
      "            \"epoch\": 99,\n",
      "            \"linear\": {\n",
      "                \"batch_size\": 1024,\n",
      "                \"num_epochs\": 100,\n",
      "                \"n_last_blocks\": 4,\n",
      "                \"avgpool_patchtokens\": false,\n",
      "                \"lr\": 0.001,\n",
      "                \"momentum\": 0.9,\n",
      "                \"wd\": 0,\n",
      "                \"val_freq\": 1\n",
      "            }\n",
      "        },\n",
      "        \"train_finetuning\": {\n",
      "            \"ckp_path_choice\": \"Official\",\n",
      "            \"ckp_path\": {\n",
      "                \"Official\": \"/storage/yue/dino_models/dino_deitsmall16_pretrain_full_checkpoint_official.pth\",\n",
      "                \"Ours\": \"/storage/yue/dino_models/vit_small_ImageNet/checkpoint0099.pth\"\n",
      "            },\n",
      "            \"batch_size\": 128,\n",
      "            \"num_epochs\": 100,\n",
      "            \"n_last_blocks\": 4,\n",
      "            \"avgpool_patchtokens\": false,\n",
      "            \"lr\": 0.001,\n",
      "            \"momentum\": 0.9,\n",
      "            \"wd\": 0,\n",
      "            \"val_freq\": 1\n",
      "        }\n",
      "    },\n",
      "    \"save_params\": {\n",
      "        \"output_dir\": \"/storage/yue/dino_models/\",\n",
      "        \"restore_epoch\": 0,\n",
      "        \"saveckp_freq\": 1,\n",
      "        \"tb_logoriginal\": true,\n",
      "        \"tb_freq\": 101,\n",
      "        \"nb_knn\": [\n",
      "            20\n",
      "        ],\n",
      "        \"temp_knn\": 0.07,\n",
      "        \"model_path\": \"/storage/yue/dino_models/vit_small_CBISDDSM_finetuning_official\"\n",
      "    },\n",
      "    \"dataset_params\": {\n",
      "        \"data_folder\": \"/storage/yue/data/\",\n",
      "        \"dataset_choice\": {\n",
      "            \"dataset_name\": \"CBISDDSM\",\n",
      "            \"ImageNet\": {\n",
      "                \"num_classes\": 1000,\n",
      "                \"knn_use_cuda\": false,\n",
      "                \"label_mapping_path\": \"data_label_mapping/ImageNet.json\"\n",
      "            },\n",
      "            \"IMAGENETTE\": {\n",
      "                \"num_classes\": 10,\n",
      "                \"knn_use_cuda\": false,\n",
      "                \"label_mapping_path\": \"data_label_mapping/ImageNet.json\"\n",
      "            },\n",
      "            \"CIFAR10\": {\n",
      "                \"num_classes\": 10,\n",
      "                \"knn_use_cuda\": false,\n",
      "                \"label_mapping_path\": \"None\"\n",
      "            },\n",
      "            \"CIFAR100\": {\n",
      "                \"num_classes\": 100,\n",
      "                \"knn_use_cuda\": true,\n",
      "                \"label_mapping_path\": \"None\"\n",
      "            },\n",
      "            \"Flower\": {\n",
      "                \"num_classes\": 102,\n",
      "                \"knn_use_cuda\": false,\n",
      "                \"label_mapping_path\": \"data_label_mapping/Flower.json\"\n",
      "            },\n",
      "            \"CBISDDSM\": {\n",
      "                \"num_classes\": 2,\n",
      "                \"knn_use_cuda\": false,\n",
      "                \"label_mapping_path\": \"None\"\n",
      "            }\n",
      "        },\n",
      "        \"augmentations\": [\n",
      "            \"RandomResizedCrop\",\n",
      "            \"RandomHorizontalFlip\",\n",
      "            \"ColorJitter\",\n",
      "            \"RandomGrayscale\",\n",
      "            \"GaussianBlur\",\n",
      "            \"Solarization\"\n",
      "        ]\n",
      "    },\n",
      "    \"dataloader_params\": {\n",
      "        \"trainloader\": {\n",
      "            \"batch_size\": 32,\n",
      "            \"batch_size_for_scheduler\": 32,\n",
      "            \"num_workers\": 10,\n",
      "            \"pin_memory\": true,\n",
      "            \"drop_last\": true\n",
      "        },\n",
      "        \"valloader\": {\n",
      "            \"batch_size\": 32,\n",
      "            \"num_workers\": 10,\n",
      "            \"pin_memory\": false,\n",
      "            \"drop_last\": false\n",
      "        }\n",
      "    },\n",
      "    \"augmentation_params\": {\n",
      "        \"global_crops_scale\": [\n",
      "            0.25,\n",
      "            1.0\n",
      "        ],\n",
      "        \"local_crops_scale\": [\n",
      "            0.05,\n",
      "            0.25\n",
      "        ],\n",
      "        \"local_crops_number\": 10,\n",
      "        \"full_size\": 256,\n",
      "        \"global_size\": 224,\n",
      "        \"local_size\": 96\n",
      "    },\n",
      "    \"model_params\": {\n",
      "        \"backbone_option\": \"vit_small\",\n",
      "        \"patch_size\": 16,\n",
      "        \"drop_path_rate\": 0.1,\n",
      "        \"out_dim\": 65536,\n",
      "        \"use_bn_in_head\": false,\n",
      "        \"norm_last_layer\": false\n",
      "    },\n",
      "    \"training_params\": {\n",
      "        \"num_epochs\": 100,\n",
      "        \"num_epochs_for_scheduler\": 100,\n",
      "        \"warmup_teacher_temp\": 0.04,\n",
      "        \"teacher_temp\": 0.07,\n",
      "        \"warmup_teacher_temp_epochs\": 30,\n",
      "        \"student_temp\": 0.1,\n",
      "        \"center_momentum\": 0.9,\n",
      "        \"optimizer\": {\n",
      "            \"name\": \"adamw\",\n",
      "            \"sgd\": {\n",
      "                \"lr\": 0,\n",
      "                \"momentum\": 0.9\n",
      "            }\n",
      "        },\n",
      "        \"lr\": {\n",
      "            \"base_lr\": 0.001,\n",
      "            \"final_lr\": 1e-05,\n",
      "            \"warmup_epochs\": 10,\n",
      "            \"start_warmup_lr\": 0\n",
      "        },\n",
      "        \"wd\": {\n",
      "            \"base_wd\": 0.04,\n",
      "            \"final_wd\": 0.4\n",
      "        },\n",
      "        \"momentum\": {\n",
      "            \"base_momentum_teacher\": 0.996,\n",
      "            \"final_momentum_teacher\": 1\n",
      "        },\n",
      "        \"clip_grad\": 0,\n",
      "        \"freeze_last_layer\": 1\n",
      "    },\n",
      "    \"system_params\": {\n",
      "        \"num_gpus\": 2,\n",
      "        \"gpu_ids\": \"0,1\",\n",
      "        \"random_seed\": 0,\n",
      "        \"use_fp16\": false\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(params_path='/home/yue3/DINO/scripts/yaml/ViT-S-16-DDSM.yaml')\n",
    "augmentation_params = args['augmentation_params']\n",
    "dataset_params = args['dataset_params']\n",
    "transforms_aug = prepare_datasets.DataAugmentationDINO(dataset_params['augmentations'], augmentation_params['global_crops_scale'],\n",
    "        augmentation_params['local_crops_scale'], augmentation_params['local_crops_number'],\n",
    "        augmentation_params['full_size'], augmentation_params['global_size'], augmentation_params['local_size'])\n",
    "transforms_plain_for_lineartrain_ddsm = transforms_aug.transforms_plain_for_lineartrain_ddsm\n",
    "transforms_plain_for_lineartrain = transforms_aug.transforms_plain_for_lineartrain\n",
    "dataset_name = dataset_params['dataset_choice']['dataset_name']\n",
    "dataset_class = prepare_datasets.GetDatasets(data_folder=dataset_params['data_folder'],\n",
    "                                                 dataset_name=dataset_name,\n",
    "                                                 knn_use_cuda=dataset_params['dataset_choice'][dataset_name]['knn_use_cuda'],\n",
    "                                                 label_mapping_path=dataset_params['dataset_choice'][dataset_name]['label_mapping_path'])\n",
    "if dataset_name == 'CBISDDSM':\n",
    "    train_plain_for_lineartrain_dataset = dataset_class.get_datasets('train/', transforms_plain_for_lineartrain_ddsm, include_index=False)\n",
    "else:\n",
    "    train_plain_for_lineartrain_dataset = dataset_class.get_datasets('train/', transforms_plain_for_lineartrain, include_index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b395a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f9e5ce442c49489a5282fafaa5d64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='i', max=2418), IntSlider(value=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@ipywidgets.interact\n",
    "def _(\n",
    "    i=ipywidgets.IntSlider(min=0, max=len(train_plain_for_lineartrain_dataset) - 1, continuous_update=False),\n",
    "    seed=ipywidgets.IntSlider(min=0, max=50, continuous_update=False),\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    original_img = train_plain_for_lineartrain_dataset[i][0]\n",
    "    print(original_img.shape)\n",
    "    _, ax_orig = plt.subplots(figsize=(15, 5))\n",
    "    ax_orig.imshow(to_numpy(original_img))\n",
    "    ax_orig.set_title(\"Original\")\n",
    "    ax_orig.axis(\"off\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2055f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
